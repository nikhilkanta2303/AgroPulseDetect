<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>


*{
    font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
  }
  body{
    background-color: #d8c046;
  }
  #imageInput{
    padding: 20px;
  }
  button{
margin-top:1.5rem;
    width: 120px;
    height: 35px;
    border-radius: 23px;
    border: none;
    background-color: black;
    color: white;
  }
  button:hover{
    background-color: #608b49;
    color: whitesmoke;
    animation: .5s;
    
  }
  #top{
    color: #608b49;
    margin-top: 5%;
  }
  #titlesplit{
    color: #2a4f27;
  }
  #title{
    font-size: 3rem;
  }
  #buttonsection{
    margin: 1.5rem;
  }


  * {
    padding: 0;
    margin: 0;
  }
  
  body {
    font-family: Arial, Tahoma, Serif;
    color: #263238;
  }
  nav {
    display: flex;
    justify-content: space-between;
    padding: 1rem 2rem;
    background: #608b49;
    color: white;
  }
  
  nav ul {
    display: flex;
    list-style: none;
  }
  
  nav li {
    padding-top: 2px;
    padding-left: 1rem;
  }
  a{
    text-decoration: none;
    color: white;
  }
#subtitle{
color:white;
padding:30px;
}
#label-container{
background-color: white;
color:black;
border-radius:23px;
max-width: 100%;
width: 40%;
}



</style>
</head>
<body>


  <nav>
    <h2>Namaste Farmer! üßë‚Äçüåæ</h2>
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="model.html">Upload and Know</a></li>
      <li><a href="#">About</a></li>
    </ul>
  </nav>

<center>
<div id="top"><h2 id="title"><span id="titlesplit">Agro</span>Pulse „ÄΩÔ∏è Detect</h2>
<p id="subtitle">Real-Time Scan</p></div>
<button type="button" onclick="init()">Start</button>
<br><br>
<div id="webcam-container"></div>
<br><br>
<div id="label-container"></div>
</center>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/_kFky0T01/";

    let model, webcam, labelContainer, maxPredictions;

    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
¬†¬†¬†¬†}
</script>
</body>
</html>
